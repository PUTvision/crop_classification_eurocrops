{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EuroCrops Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assists with exploring the EuroCrops demo dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache location: /home/przemek/Projects/pp/eurocrops/notebooks/cachedir\n"
     ]
    }
   ],
   "source": [
    "from joblib import Memory\n",
    "location = os.path.abspath('./cachedir')\n",
    "print(f'cache location: {location}')\n",
    "memory = Memory(location, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_PATH = '/media/data/local/eurocrops/m1615987/'\n",
    "H5_FILE_PATH = os.path.join(ROOT_DATA_PATH, 'HDF5s/train/AT_T33UWP_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CHANNELS = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data_from_h5_file(h5_file_path):\n",
    "    hdf = pd.HDFStore(h5_file_path, mode='r') #here we directly load the .h5 file in one go using pandas.\n",
    "    region_names = hdf.keys()  #list all the keys or regions in the region (for eg- AT112)\n",
    "    region_names = region_names[1:3]\n",
    "    df_datas = []\n",
    "\n",
    "    for region_name in tqdm(region_names):\n",
    "        df_data_single = hdf.get(f'/{region_name}') #selecting a region from based on the key (AT112 for eg.)\n",
    "        df_datas.append(df_data_single)\n",
    "    \n",
    "    #len(set.union(*[set(x.columns) for x in df_datas]))  120 columns now, but for one region there are only 80, intesection 44\n",
    "    #len(set.intersection(*[set(x.columns) for x in df_datas]))  # 120 columns now, but for one region there are only 80\n",
    "    \n",
    "    return df_datas, region_names\n",
    "        \n",
    "\n",
    "def _find_closest_non_zero_column(time_index, common_days, dates_list, row):\n",
    "    # this time step is zero, we needto find another one that is not zero.\n",
    "    # To do it, find all closest non-zero columns (for all time steps for this row) \n",
    "        \n",
    "    time_distance_to_nonzero_columns = [abs(common_days[time_index] - v) for v in dates_list]\n",
    "    for k in range(len(time_distance_to_nonzero_columns)):\n",
    "        if not np.any(row.iloc[k]):\n",
    "            time_distance_to_nonzero_columns[k] = 9999\n",
    "    closest_nonzero_column = np.argmin(time_distance_to_nonzero_columns)\n",
    "    return closest_nonzero_column\n",
    "\n",
    "    \n",
    "def _resample_and_concatenate_regions_data(df_datas, resampled_days_interval):\n",
    "    # Conatenation of data with different dates - fixed interval span, with finding closes date (better to use interpolation, but not with nois cloud data)\n",
    "    DI = resampled_days_interval  # days interval\n",
    "    common_days = list(range(DI, 365, DI))\n",
    "    print(f'len(common_days) = {len(common_days)}')\n",
    "    # common_days_datetime = [for day in common_days]\n",
    "\n",
    "    # year = int(timesteps[10][:4])\n",
    "    # new_year_day = dt.datetime(year=year, month=1, day=1)\n",
    "    # dates_list = [((dt.datetime.strptime(date, tf)- new_year_day).days + 1) for date in timesteps]\n",
    "\n",
    "    df_data_all = pd.DataFrame(columns=common_days)\n",
    "\n",
    "\n",
    "    for df_data_single in tqdm(df_datas):\n",
    "        timesteps = list(df_data_single.columns)\n",
    "        year = int(timesteps[10][:4])\n",
    "        new_year_day = dt.datetime(year=year, month=1, day=1)\n",
    "        tf = '%Y%m%d'\n",
    "        dates_list = [((dt.datetime.strptime(date, tf)- new_year_day).days + 1) for date in timesteps]\n",
    "        df_data_single = df_data_single.rename(columns={old: new for old, new in zip(timesteps, dates_list)})\n",
    "\n",
    "        closest_columns = []\n",
    "        for common_day in common_days:\n",
    "            closest_column = np.argmin([abs(common_day - v) for v in dates_list])\n",
    "            closest_columns.append(closest_column)\n",
    "\n",
    "        new_frames = []\n",
    "        for index, row in df_data_single.iterrows():\n",
    "            resampled_row_data = []\n",
    "            \n",
    "            for i, closest_column in enumerate(closest_columns):\n",
    "                rc = row.iloc[closest_column]\n",
    "                all_zeros = not np.any(rc)\n",
    "                if all_zeros:\n",
    "                    closest_nonzero_column = _find_closest_non_zero_column(\n",
    "                        time_index=i,\n",
    "                        common_days=common_days,\n",
    "                        dates_list=dates_list, \n",
    "                        row=row)\n",
    "                    rc = row.iloc[closest_nonzero_column]\n",
    "                \n",
    "                resampled_row_data.append(rc)\n",
    "\n",
    "            resampled_row_df = pd.DataFrame([resampled_row_data], columns=common_days, index=[index])\n",
    "            new_frames.append(resampled_row_df)\n",
    "\n",
    "        new_frames_df = pd.concat(new_frames)\n",
    "        df_data_all = pd.concat([df_data_all, new_frames_df])\n",
    "    \n",
    "    return df_data_all, common_days\n",
    "\n",
    "\n",
    "def _load_all_labels(region_names):\n",
    "    df_labels_all_lists = []\n",
    "    for region_name in region_names:\n",
    "        region_name = region_name.strip('/')\n",
    "        LABELS_CSV_FILE_PATH = os.path.join(ROOT_DATA_PATH, f'csv_labels/train/demo_eurocrops_{region_name}.csv')\n",
    "        GEO_JSON_FILE_PATH = os.path.join(ROOT_DATA_PATH, f'GeoJSONs_regional_split/train/AT/demo_eurocrops_{region_name}.geojson')\n",
    "\n",
    "        # csv_file_path = os.path.join(train_csv_dir, csv_file_name)\n",
    "        df_labels = pd.read_csv(LABELS_CSV_FILE_PATH, index_col=0)\n",
    "        df_labels_all_lists.append(df_labels)\n",
    "\n",
    "\n",
    "    df_labels_all = pd.concat(df_labels_all_lists)\n",
    "    return df_labels_all\n",
    "    \n",
    "\n",
    "global df_datas\n",
    "@memory.cache\n",
    "def load_all_data_from_file_resampled(\n",
    "        h5_file_path: str, \n",
    "        resampled_days_interval: int,\n",
    "        ):\n",
    "    global df_datas\n",
    "    df_datas, region_names = _load_data_from_h5_file(h5_file_path=h5_file_path)\n",
    "    df_data_all, common_days = _resample_and_concatenate_regions_data(df_datas=df_datas, resampled_days_interval=resampled_days_interval)\n",
    "    \n",
    "    df_labels_all = _load_all_labels(region_names=region_names)\n",
    "\n",
    "    return df_data_all, df_labels_all, common_days, region_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                   | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "df_data_all, df_labels_all, common_days, region_names = load_all_data_from_file_resampled(\n",
    "    h5_file_path=H5_FILE_PATH, \n",
    "    resampled_days_interval=7,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datas[0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the data for one parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the first row\n",
    "example_row = df_data_all.iloc[0]\n",
    "parcel_ID = example_row.name\n",
    "\n",
    "# Get the corresponding label\n",
    "label_code = df_labels_all.loc[parcel_ID]['crpgrpc']\n",
    "label_name = df_labels_all.loc[parcel_ID]['crpgrpn']\n",
    "\n",
    "print('{} grows on parcel {}'.format(label_name, parcel_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row_np = example_row.to_numpy()\n",
    "example_row_np = np.stack(example_row_np, axis=0)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "plt.plot(common_days, example_row_np)\n",
    "# plt.legend(bands)\n",
    "plt.style.use('_classic_test_patch')\n",
    "plt.xlabel('day of year')\n",
    "plt.ylabel('channel value')\n",
    "plt.title(f'Data for parcel id {parcel_ID}')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geometry_dict_by_parcelid_all(region_names):\n",
    "    geometry_dict_by_parcelid_all = {}\n",
    "    for region_name in tqdm(region_names):\n",
    "        region_name = region_name.strip('/')\n",
    "        GEO_JSON_FILE_PATH = os.path.join(ROOT_DATA_PATH, f'GeoJSONs_regional_split/train/AT/demo_eurocrops_{region_name}.geojson')    \n",
    "\n",
    "        with open(GEO_JSON_FILE_PATH, 'r') as file:\n",
    "            geojson_data = json.load(file)\n",
    "\n",
    "        geometry_dict_by_parcelid = {feature['properties']['recno']: feature['geometry'] \n",
    "                                     for feature in geojson_data['features']}\n",
    "        geometry_dict_by_parcelid_all.update(geometry_dict_by_parcelid)\n",
    "    return geometry_dict_by_parcelid_all\n",
    "\n",
    "\n",
    "geometry_dict_by_parcelid_all = load_geometry_dict_by_parcelid_all(region_names=region_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_dict_by_parcelid_all[parcel_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check crop types in the current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_types_counts_and_ids(df_data_all, df_labels_all):\n",
    "    crop_types_counts = {}\n",
    "    crop_types_ids = {}\n",
    "\n",
    "    regions_id_set = set(df_data_all.index)\n",
    "    \n",
    "    for i, region_id in enumerate(df_labels_all.index):\n",
    "        if region_id not in regions_id_set:\n",
    "            continue\n",
    "\n",
    "        crop_name = df_labels_all.iloc[i]['crpgrpn']\n",
    "        current_count = crop_types_counts.get(crop_name, 0) \n",
    "        crop_types_counts[crop_name] = current_count + 1\n",
    "\n",
    "        if crop_name not in crop_types_ids:\n",
    "            crop_types_ids[crop_name] = []\n",
    "        crop_types_ids[crop_name].append(region_id)\n",
    "    \n",
    "    return crop_types_counts, crop_types_ids\n",
    "\n",
    "\n",
    "        \n",
    "crop_types_counts, crop_types_ids = get_crop_types_counts_and_ids(df_data_all=df_data_all, df_labels_all=df_labels_all)\n",
    "\n",
    "print(f'Total crop fields: {sum(crop_types_counts.values())}')\n",
    "crop_types_counts = {k: v for k, v in sorted(crop_types_counts.items(), key=lambda item: -item[1])}\n",
    "crop_types_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_labels_all), len(df_data_all), len(geometry_dict_by_parcelid_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_crop_names = [\n",
    "    'nuts',  # 'millet'\n",
    "    'sugar_beet',\n",
    "    'hemp',\n",
    "    # 'sunflower_and_yellow_bloomer',\n",
    "    #'soya',\n",
    "    #'millet',\n",
    "    #'grain_maize',\n",
    "    #'pasture_meadow',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def get_data_for_crop_type(crop_name):\n",
    "    data = np.zeros(shape=(len(crop_types_ids[crop_name]), len(common_days), NUMBER_OF_CHANNELS), dtype=float)\n",
    "    for i, region_id in enumerate(crop_types_ids[crop_name]):\n",
    "        region_data = df_data_all.loc[region_id].to_numpy()\n",
    "        data[i, ...] = np.stack(region_data)\n",
    "    return data\n",
    "    \n",
    "    \n",
    "selected_crops_data = [get_data_for_crop_type(crop_name) for crop_name in selected_crop_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{selected_crops_data[0].shape} = [fields (for the crop type), time (common_days), channels (bands B0-B12)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_index = 0\n",
    "\n",
    "data_crop_x = selected_crops_data[crop_index]\n",
    "data_crop_x_mean = np.mean(data_crop_x, axis=0)\n",
    "data_crop_x_std = np.std(data_crop_x, axis=0)\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "plt.plot(common_days, data_crop_x_mean)\n",
    "# plt.legend(bands)\n",
    "plt.style.use('_classic_test_patch')\n",
    "plt.xlabel('day of year')\n",
    "plt.ylabel('channel value')\n",
    "plt.title(f'Data for crop \"{selected_crop_names[crop_index]}\"')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = selected_crops_data[0]\n",
    "d[0, :, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CropNdviData:\n",
    "    mean: np.ndarray\n",
    "    std: np.ndarray\n",
    "\n",
    "        \n",
    "def get_ndvi_data(data_crop) -> CropNdviData:\n",
    "    \"\"\"\n",
    "    data_crop: [fields (for the crop), time (common_days), channels (bands B0-B12)]')\n",
    "    return: mean and std for ndvi \"channel\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # B8-B4 / (B8+B4)   ( counting from B1 to B13)\n",
    "    B4 = data_crop[:, :, 4-1]\n",
    "    B8 = data_crop[:, :, 8-1]\n",
    "\n",
    "    data_crop_ndvi = (B8 - B4) / (B8 + B4)\n",
    "    data_crop_mean_ndvi = np.mean(data_crop_ndvi, axis=0)\n",
    "    data_crop_std_ndvi = np.std(data_crop_ndvi, axis=0) \n",
    "    \n",
    "    return CropNdviData(mean=data_crop_mean_ndvi, std=data_crop_std_ndvi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_crops_ndvi_data = [get_ndvi_data(crop_data) for crop_data in selected_crops_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_index = 0\n",
    "\n",
    "data_crop_x_mean_ndvi = selected_crops_ndvi_data[crop_index].mean\n",
    "data_crop_x_std_ndvi = selected_crops_ndvi_data[crop_index].std\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "plt.plot(common_days, data_crop_x_mean_ndvi)\n",
    "plt.plot(common_days, data_crop_x_mean_ndvi - data_crop_x_std_ndvi, ':', color='b', linewidth=0.7)\n",
    "plt.plot(common_days, data_crop_x_mean_ndvi + data_crop_x_std_ndvi, ':', color='b', linewidth=0.7)\n",
    "\n",
    "# plt.legend(bands)\n",
    "plt.style.use('_classic_test_patch')\n",
    "plt.xlabel('day of year')\n",
    "plt.ylabel('channel value')\n",
    "plt.title(f'NDVI data for crop \"{selected_crop_names[crop_index]}\"')\n",
    "plt.grid()\n",
    "plt.legend(['mean NDVI', '+- std NDVI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "\n",
    "for crop_ndvi_data in selected_crops_ndvi_data:\n",
    "    plt.plot(common_days, crop_ndvi_data.mean)\n",
    "\n",
    "# plt.legend(bands)\n",
    "plt.style.use('_classic_test_patch')\n",
    "plt.xlabel('day of year')\n",
    "plt.ylabel('NDVI value (())')\n",
    "plt.title(f'mean NDVI data for crop \"{selected_crop_names[crop_index]}\"')\n",
    "plt.grid()\n",
    "plt.legend(selected_crop_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
